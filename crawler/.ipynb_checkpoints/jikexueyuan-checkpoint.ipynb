{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正则表达式符号与方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常用符号"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 常用符号：点号，星号，问号与括号\n",
    "- 常用方法：findall, search, sub\n",
    "- 常用方法：.\n",
    "    - . : 匹配任意字符，换行符\\n除外\n",
    "    - * ：匹配前一个字符0次或无限次\n",
    "    - ? ：匹配前一个字符0次或1次\n",
    "    - .*：贪心算法\n",
    "    - .*?：非贪心算法\n",
    "    - （）：括号内的数据作为结果返回\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 效果展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- findall： 匹配所有符合规律的内容，返回包含结果的列表\n",
    "- Search：匹配并提取第一个符合规律的内容，返回一个正则表达式对象（object)\n",
    "- Sub：替换符合规律的内容，返回替换后的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常用技巧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- import re    \n",
    "- from re import * \n",
    "- from re import findall,search,sub,S\n",
    "- 不需要complie\n",
    "- 使用\\d+匹配纯数字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正则表达式的应用举例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用findall与search从大量文本中匹配感兴趣的内容\n",
    "- 使用sub实现换页功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 匹配多段内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 灵活使用findall与search\n",
    "- 先抓大再抓小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中文乱码与header问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "head = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.118 Safari/537.36'}\n",
    "html = requests.get('http://jp.tingroom.com/yuedu/yd300p/',headers = head)\n",
    "html.encoding = 'utf-8' #这一行是将编码转为utf-8否则中文会显示乱码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post请求方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://www.crowdfunder.com/browse/deals&template=false'\n",
    "data = {\n",
    "    'entities_only':'true',\n",
    "    'page':'2'\n",
    "}\n",
    "html_post = requests.post(url, data=data)\n",
    "title = re.findall('\"card-title\">(.*?)</div>',html_post.text,re.S)\n",
    "for each in title:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抓取极客学院课程信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class spider:\n",
    "    def __init__(self):\n",
    "        print(\"开始爬取内容\")\n",
    "        \n",
    "    # 获取网页源代码\n",
    "    def getsource(self, url):\n",
    "        html = requests.get(url)\n",
    "        return html.text\n",
    "    \n",
    "    # 用来生成不同页数的链接\n",
    "    def change_page(self, url, total_page):\n",
    "        now_page = int(re.search(\"pageNum=(\\d+)\", url, re.S).group(1))\n",
    "        page_group = []\n",
    "        for i in range(now_page, total_page + 1):\n",
    "            link = re.sub(\"pageNum=\\d+\", \"pageNum=%s\" %i, url, re.S)\n",
    "            page_group.append(link)\n",
    "        return page_group\n",
    "    \n",
    "    # 抓取每个课程块的信息\n",
    "    def get_every_class(self, source):\n",
    "        everyclass = re.findall('(<li id=\".*?</li>)', source, re.S)\n",
    "        return everyclass\n",
    "    \n",
    "    # 从每个课程块中提取我们需要的信息\n",
    "    def getinfo(self, eachclass):\n",
    "        info = {}\n",
    "        info[\"title\"] = re.search('\" class=\"lessonimg\" title=\"(.*?)\" alt=\"', eachclass, re.S).group(1).strip()\n",
    "        info[\"content\"] = re.search('<p style=\"height: 0px; opacity: 0; display: none;\">(.*?)</p>', eachclass, re.S).group(1).strip()\n",
    "        timeandlevel = re.findall('<em>(.*?)</em>', eachclass, re.S)\n",
    "        info[\"classtime\"] = timeandlevel[0].strip().replace(\"\\t\", \"\").replace(\"\\n\", \" \")\n",
    "        info[\"classlevel\"] = timeandlevel[1].strip()\n",
    "        info['learnnum'] = re.search('\"learn-number\">(.*?)</em>',eachclass, re.S).group(1).strip()\n",
    "        return info\n",
    "    \n",
    "    # 保存结果到info.txt文件中\n",
    "    def saveinfo(self, classinfo):\n",
    "        with open(\"info.txt\", \"a\", encoding=\"gbk\") as f:\n",
    "            for each in classinfo:\n",
    "                f.writelines(\"title:\" + each[\"title\"] + \"\\n\")\n",
    "                f.writelines(\"content:\" + each[\"content\"] + \"\\n\")\n",
    "                f.writelines(\"classtime:\" + each[\"classtime\"] + \"\\n\")\n",
    "                f.writelines(\"classlevel:\" + each[\"classlevel\"] + \"\\n\")\n",
    "                f.writelines(\"learnnum:\" + each[\"learnnum\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始爬取内容\n",
      "正在处理页面：http://www.jikexueyuan.com/course/?pageNum=1\n",
      "正在处理页面：http://www.jikexueyuan.com/course/?pageNum=2\n",
      "正在处理页面：http://www.jikexueyuan.com/course/?pageNum=3\n",
      "正在处理页面：http://www.jikexueyuan.com/course/?pageNum=4\n",
      "正在处理页面：http://www.jikexueyuan.com/course/?pageNum=5\n",
      "内容爬取完成\n"
     ]
    }
   ],
   "source": [
    "classinfo = []\n",
    "url = \"http://www.jikexueyuan.com/course/?pageNum=1\"\n",
    "jikespider = spider()\n",
    "all_links = jikespider.change_page(url, 5)\n",
    "for link in all_links:\n",
    "    print(\"正在处理页面：\" + link)\n",
    "    html = jikespider.getsource(link)\n",
    "    everyclass = jikespider.get_every_class(html)\n",
    "    for each in everyclass:\n",
    "        info = jikespider.getinfo(each)\n",
    "        classinfo.append(info)\n",
    "jikespider.saveinfo(classinfo)\n",
    "print(\"内容爬取完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
