{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语料加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv(\"data/stopwords.txt\", quoting=3, index_col=False, sep=\"\\t\", names=[\"stopword\"], encoding=\"utf-8\")\n",
    "stopwords = stopwords[\"stopword\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "laogong_df = pd.read_csv(\"data/beilaogongda.csv\", encoding=\"utf-8\")\n",
    "laopo_df = pd.read_csv(\"data/beilaopoda.csv\", encoding=\"utf-8\")\n",
    "erzi_df = pd.read_csv(\"data/beierzida.csv\", encoding=\"utf-8\")\n",
    "nver_df = pd.read_csv(\"data/beinverda.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "laogong_df.dropna(inplace=True)\n",
    "laopo_df.dropna(inplace=True)\n",
    "erzi_df.dropna(inplace=True)\n",
    "nver_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "laogong = laogong_df.segment.values.tolist()\n",
    "laopo = laopo_df.segment.values.tolist()\n",
    "erzi = erzi_df.segment.values.tolist()\n",
    "nver = nver_df.segment.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分词和去停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_text(content_lines, sentences, category):\n",
    "    for line in content_lines:\n",
    "        try:\n",
    "            segs = jieba.lcut(line)\n",
    "            # 去空格\n",
    "            segs = list(filter(lambda x: x.strip(), segs))\n",
    "            # 去数字\n",
    "            segs = [v for v in segs if not str(v).isdigit()]\n",
    "            # 去长度为1的字符\n",
    "            segs = list(filter(lambda x: len(x) > 1, segs))\n",
    "            # 去掉停用词\n",
    "            segs = list(filter(lambda x: x not in stopwords, segs))\n",
    "            sentences.append(((\" \").join(segs), category))\n",
    "        except Exception as e:\n",
    "            print(line, str(e))\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "preprocess_text(laogong, sentences, 0)\n",
    "preprocess_text(laopo, sentences, 1)\n",
    "preprocess_text(erzi, sentences, 2)\n",
    "preprocess_text(nver, sentences, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('报警 人称 女儿 民警 到场', 3),\n",
       " ('报警 女儿 持械 民警 到场', 3),\n",
       " ('报警 儿子 持械 民警 到场', 2),\n",
       " ('报警 人称 民警 走后 老公 民警 到场', 0),\n",
       " ('报警 妻子 一拳 无需 救护 民警 携带 防护 设备', 1)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抽取词向量特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer(\n",
    "    analyzer=\"word\",\n",
    "    max_features=4000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x, y = zip(*sentences) #矩阵的行列转换\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=4000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(vec.transform(x_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估、计算AUC值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9952267303102625"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(vec.transform(x_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型对比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改变特征向量模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=20000, min_df=1,\n",
       "        ngram_range=(1, 4), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(\n",
    "    analyzer=\"word\",\n",
    "    ngram_range=(1, 4),\n",
    "    max_features=20000\n",
    ")\n",
    "\n",
    "vec.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(vec.transform(x_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9880668257756563"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(vec.transform(x_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改变训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9976133651551312"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel=\"linear\")\n",
    "svm.fit(vec.transform(x_train), y_train)\n",
    "\n",
    "svm.score(vec.transform(x_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xbg_train = xgb.DMatrix(vec.transform(x_train), label=y_train)\n",
    "sgb_test = xgb.DMatrix(vec.transform(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ps.不会用，这块后面再深究"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost的调参指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    params = {  \n",
    "            'booster': 'gbtree',     #使用gbtree\n",
    "            'objective': 'multi:softmax',  # 多分类的问题、  \n",
    "            # 'objective': 'multi:softprob',   # 多分类概率  \n",
    "            #'objective': 'binary:logistic',  #二分类\n",
    "            'eval_metric': 'merror',   #logloss\n",
    "            'num_class': 4,  # 类别数，与 multisoftmax 并用  \n",
    "            'gamma': 0.1,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。  \n",
    "            'max_depth': 8,  # 构建树的深度，越大越容易过拟合  \n",
    "            'alpha': 0,   # L1正则化系数  \n",
    "            'lambda': 10,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。  \n",
    "            'subsample': 0.7,  # 随机采样训练样本  \n",
    "            'colsample_bytree': 0.5,  # 生成树时进行的列采样  \n",
    "            'min_child_weight': 3,  \n",
    "            # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言  \n",
    "            # 假设 h 在 0.01 附近，min_child_weight 为 1 叶子节点中最少需要包含 100 个样本。  \n",
    "            'silent': 0,  # 设置成1则没有运行信息输出，最好是设置为0.  \n",
    "            'eta': 0.03,  # 如同学习率  \n",
    "            'seed': 1000,  \n",
    "            'nthread': -1,  # cpu 线程数  \n",
    "            'missing': 1 \n",
    "        }  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整个示例代码可以当做模板来用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从优化和提高模型准确率来说，主要有两方面可以尝试："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 特征向量的构建，除了词袋模型，可以考虑使用 word2vec 和 doc2vec 等；\n",
    "- 模型上可以选择有监督的分类算法、集成学习以及神经网络等。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
